{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d974a98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T14:40:15.526302Z",
     "iopub.status.busy": "2024-12-24T14:40:15.525909Z",
     "iopub.status.idle": "2024-12-24T14:40:17.488720Z",
     "shell.execute_reply": "2024-12-24T14:40:17.487370Z"
    },
    "papermill": {
     "duration": 1.968106,
     "end_time": "2024-12-24T14:40:17.490307",
     "exception": false,
     "start_time": "2024-12-24T14:40:15.522201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "\n",
      "Generating predictions on test set...\n",
      "Predictions:\n",
      "    credit_score  risk_probability risk_category\n",
      "0         775.0               0.5     Very Good\n",
      "\n",
      "Feature Importance:\n",
      "                  feature  importance\n",
      "0           annual_income         0.0\n",
      "1              total_debt         0.0\n",
      "2         monthly_payment         0.0\n",
      "3            credit_limit         0.0\n",
      "4         current_balance         0.0\n",
      "5       account_age_years         0.0\n",
      "6       late_payments_30d         0.0\n",
      "7       late_payments_60d         0.0\n",
      "8       employment_status         0.0\n",
      "9          housing_status         0.0\n",
      "10         debt_to_income         0.0\n",
      "11      payment_to_income         0.0\n",
      "12     credit_utilization         0.0\n",
      "13  credit_history_factor         0.0\n",
      "14  payment_history_score         0.0\n",
      "\n",
      "Model Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "class CreditScoringModel:\n",
    "    \"\"\"\n",
    "    A credit scoring model using XGBoost.\n",
    "\n",
    "    Attributes:\n",
    "        scaler (StandardScaler): Scaler for numerical feature normalization.\n",
    "        label_encoders (dict): Dictionary of LabelEncoders for categorical features.\n",
    "        model (xgb.XGBClassifier): The trained XGBoost model.\n",
    "        feature_importance (pd.DataFrame): Feature importance after training.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoders = {}\n",
    "        self.model = None\n",
    "        self.feature_importance = None\n",
    "\n",
    "    def preprocess_features(self, data):\n",
    "        \"\"\"\n",
    "        Preprocess raw credit application data by handling missing values\n",
    "        and encoding categorical variables.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): The raw dataset.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The preprocessed dataset.\n",
    "        \"\"\"\n",
    "        df = data.copy()\n",
    "        \n",
    "        # Separate numeric and categorical columns\n",
    "        numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "        categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "        \n",
    "        # Fill missing numeric values with median\n",
    "        for col in numerical_columns:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "            \n",
    "        # Fill missing categorical values with mode\n",
    "        for col in categorical_columns:\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "            \n",
    "        # Encode categorical features\n",
    "        for col in categorical_columns:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "            df[col] = self.label_encoders[col].fit_transform(df[col])\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def engineer_features(self, data):\n",
    "        \"\"\"\n",
    "        Create engineered features to improve predictive power.\n",
    "        Includes debt-to-income ratio, payment-to-income ratio,\n",
    "        credit utilization, and other derived measures.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): The preprocessed dataset.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The dataset with new feature columns.\n",
    "        \"\"\"\n",
    "        df = data.copy()\n",
    "        \n",
    "        # Debt-to-Income Ratio\n",
    "        if 'annual_income' in df.columns and 'total_debt' in df.columns:\n",
    "            df['debt_to_income'] = df['total_debt'] / df['annual_income']\n",
    "            \n",
    "        # Payment-to-Income Ratio\n",
    "        if 'monthly_payment' in df.columns and 'annual_income' in df.columns:\n",
    "            df['payment_to_income'] = (df['monthly_payment'] * 12) / df['annual_income']\n",
    "            \n",
    "        # Credit Utilization\n",
    "        if 'current_balance' in df.columns and 'credit_limit' in df.columns:\n",
    "            df['credit_utilization'] = df['current_balance'] / df['credit_limit']\n",
    "            \n",
    "        # Log-transformed length of credit history\n",
    "        if 'account_age_years' in df.columns:\n",
    "            df['credit_history_factor'] = np.log1p(df['account_age_years'])\n",
    "            \n",
    "        # Payment History Score\n",
    "        if 'late_payments_30d' in df.columns and 'late_payments_60d' in df.columns and 'account_age_years' in df.columns:\n",
    "            # Example weighting: 30-day lates get half the weight of 60-day lates\n",
    "            df['payment_history_score'] = 1 - (\n",
    "                (df['late_payments_30d'] * 0.5 + df['late_payments_60d']) / \n",
    "                df['account_age_years'].replace(0, 1)  # Avoid division by zero\n",
    "            )\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def calculate_risk_score(self, features):\n",
    "        \"\"\"\n",
    "        Convert XGBoost predicted probability (of 'bad credit') into a\n",
    "        FICO-like risk score on a 300-850 scale.\n",
    "\n",
    "        Args:\n",
    "            features (np.ndarray): Numpy array of scaled features.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Array of risk scores (300 - 850).\n",
    "        \"\"\"\n",
    "        base_score = 500  # Starting reference point\n",
    "        score_range = 550  # (850 - 300)\n",
    "        \n",
    "        # Probability that applicant is \"bad\" (class 1)\n",
    "        risk_proba = self.model.predict_proba(features)[:, 1]\n",
    "        \n",
    "        # Higher probability of bad credit -> lower score\n",
    "        risk_score = base_score + (score_range * (1 - risk_proba))\n",
    "        \n",
    "        # Clip scores to valid range\n",
    "        risk_score = np.clip(risk_score, 300, 850)\n",
    "        \n",
    "        return risk_score\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Train the credit scoring model using XGBoost.\n",
    "        \n",
    "        Args:\n",
    "            X_train (pd.DataFrame): Training feature set.\n",
    "            y_train (np.ndarray): Training labels.\n",
    "        \"\"\"\n",
    "        # Preprocess and engineer features\n",
    "        X_processed = self.preprocess_features(X_train)\n",
    "        X_engineered = self.engineer_features(X_processed)\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X_engineered)\n",
    "        \n",
    "        # Initialize and train the XGBoost model\n",
    "        self.model = xgb.XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            n_estimators=100,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.model.fit(X_scaled, y_train)\n",
    "        \n",
    "        # Retrieve feature importance\n",
    "        self.feature_importance = pd.DataFrame({\n",
    "            'feature': X_engineered.columns,\n",
    "            'importance': self.model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict credit risk scores for new applications.\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): Feature set to predict on.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Risk assessment containing credit scores,\n",
    "                          risk probabilities, and risk categories.\n",
    "        \"\"\"\n",
    "        # Preprocess and engineer features\n",
    "        X_processed = self.preprocess_features(X)\n",
    "        X_engineered = self.engineer_features(X_processed)\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.transform(X_engineered)\n",
    "        \n",
    "        # Compute credit scores\n",
    "        risk_scores = self.calculate_risk_score(X_scaled)\n",
    "        \n",
    "        # Classify into categories\n",
    "        risk_probs = self.model.predict_proba(X_scaled)[:, 1]\n",
    "        risk_assessment = pd.DataFrame({\n",
    "            'credit_score': risk_scores,\n",
    "            'risk_probability': risk_probs,\n",
    "            'risk_category': pd.cut(\n",
    "                risk_scores, \n",
    "                bins=[0, 580, 670, 740, 800, 850],\n",
    "                labels=['Poor', 'Fair', 'Good', 'Very Good', 'Excellent']\n",
    "            )\n",
    "        })\n",
    "        \n",
    "        return risk_assessment\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"\n",
    "        Retrieve the importance of each feature in the model.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Feature importance sorted by descending importance.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the model has not been trained yet.\n",
    "        \"\"\"\n",
    "        if self.feature_importance is None:\n",
    "            raise ValueError(\"Model hasn't been trained yet\")\n",
    "        return self.feature_importance\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance on a test set.\n",
    "\n",
    "        Args:\n",
    "            X_test (pd.DataFrame): Test feature set.\n",
    "            y_test (np.ndarray): True labels.\n",
    "\n",
    "        Returns:\n",
    "            dict: Contains the classification report and confusion matrix.\n",
    "        \"\"\"\n",
    "        # Preprocess, engineer, and scale test features\n",
    "        X_processed = self.preprocess_features(X_test)\n",
    "        X_engineered = self.engineer_features(X_processed)\n",
    "        X_scaled = self.scaler.transform(X_engineered)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = self.model.predict(X_scaled)\n",
    "        \n",
    "        # Performance metrics\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        return {\n",
    "            'classification_report': report,\n",
    "            'confusion_matrix': conf_matrix\n",
    "        }\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Demonstration of how to use the CreditScoringModel with sample data.\n",
    "    Note: Sample data is tiny and only for illustrative purposes.\n",
    "    \"\"\"\n",
    "    # Sample data (only 3 rows, not realistic for any production scenario)\n",
    "    sample_data = pd.DataFrame({\n",
    "        'annual_income': [50000, 75000, 100000],\n",
    "        'total_debt': [15000, 25000, 30000],\n",
    "        'monthly_payment': [500, 800, 1000],\n",
    "        'credit_limit': [10000, 15000, 20000],\n",
    "        'current_balance': [3000, 7500, 12000],\n",
    "        'account_age_years': [2, 5, 8],\n",
    "        'late_payments_30d': [1, 0, 0],\n",
    "        'late_payments_60d': [0, 0, 0],\n",
    "        'employment_status': ['employed', 'employed', 'self_employed'],\n",
    "        'housing_status': ['rent', 'own', 'own']\n",
    "    })\n",
    "    \n",
    "    # Sample labels (0 = good credit, 1 = bad credit)\n",
    "    sample_labels = np.array([0, 0, 1])\n",
    "    \n",
    "    # Instantiate and train the model\n",
    "    model = CreditScoringModel()\n",
    "    \n",
    "    # Train/Test split (warning: only 3 samples, purely illustrative!)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        sample_data, sample_labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"Training the model...\")\n",
    "    model.train(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions\n",
    "    print(\"\\nGenerating predictions on test set...\")\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"Predictions:\\n\", predictions)\n",
    "    \n",
    "    # Feature importance\n",
    "    print(\"\\nFeature Importance:\")\n",
    "    feature_imp = model.get_feature_importance()\n",
    "    print(feature_imp)\n",
    "    \n",
    "    # Evaluation\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    evaluation = model.evaluate(X_test, y_test)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(evaluation['classification_report'])\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(evaluation['confusion_matrix'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.67054,
   "end_time": "2024-12-24T14:40:18.111221",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-24T14:40:13.440681",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
